{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Neural Networks(INNDL)_R6_Project1_customerchurn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emms8XOjLVBj",
        "colab_type": "text"
      },
      "source": [
        "Mounting the drive with colab to access the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLhBGZ6bVYvT",
        "colab_type": "code",
        "outputId": "e73519de-c54f-4550-a094-489c6d76210c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PELiLgxWaUM",
        "colab_type": "text"
      },
      "source": [
        "### **Customer churn prediction using Neural Networks**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMRyPKT0WJgA",
        "colab_type": "text"
      },
      "source": [
        "**Importing the necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KWjSbX5WIG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt   \n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "%matplotlib inline \n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score, auc, roc_curve\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR5WtVrxPDeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Reading the CSV file from drive\n",
        "churn=pd.read_csv(\"gdrive/My Drive/AIML/bank.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cniev_WoWDeq",
        "colab_type": "code",
        "outputId": "10e251a4-a89e-41ef-8bd4-6607d5587fa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Checking the dimension of the dataset\n",
        "churn.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUCE61MqURly",
        "colab_type": "code",
        "outputId": "bc37ffc9-0fa1-4890-e56e-9ecdc10ed01a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "## Getting the info about the datatypes and null/non-null value counts in each column\n",
        "churn.info()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            "RowNumber          10000 non-null int64\n",
            "CustomerId         10000 non-null int64\n",
            "Surname            10000 non-null object\n",
            "CreditScore        10000 non-null int64\n",
            "Geography          10000 non-null object\n",
            "Gender             10000 non-null object\n",
            "Age                10000 non-null int64\n",
            "Tenure             10000 non-null int64\n",
            "Balance            10000 non-null float64\n",
            "NumOfProducts      10000 non-null int64\n",
            "HasCrCard          10000 non-null int64\n",
            "IsActiveMember     10000 non-null int64\n",
            "EstimatedSalary    10000 non-null float64\n",
            "Exited             10000 non-null int64\n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQbVrrwtU2hP",
        "colab_type": "code",
        "outputId": "c54adea2-16b2-49d6-864b-d6745ab41eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "## Displaying the first few columns of the dataset\n",
        "churn.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLZlXJOmV0cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Dropping the columns that are not needed for the analysis\n",
        "churn=churn.drop(['RowNumber','CustomerId','Surname'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9U352HeWLET",
        "colab_type": "code",
        "outputId": "e60e2a11-32bf-47a7-f3ab-48fd556e9d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Checking the dimension after dropping columns\n",
        "churn.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8XclHEXYOle",
        "colab_type": "code",
        "outputId": "f52a8790-bf59-4a66-f19f-f05b150ec2ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "## Checking the info on datatype and null value after columns drop\n",
        "churn.info()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 11 columns):\n",
            "CreditScore        10000 non-null int64\n",
            "Geography          10000 non-null object\n",
            "Gender             10000 non-null object\n",
            "Age                10000 non-null int64\n",
            "Tenure             10000 non-null int64\n",
            "Balance            10000 non-null float64\n",
            "NumOfProducts      10000 non-null int64\n",
            "HasCrCard          10000 non-null int64\n",
            "IsActiveMember     10000 non-null int64\n",
            "EstimatedSalary    10000 non-null float64\n",
            "Exited             10000 non-null int64\n",
            "dtypes: float64(2), int64(7), object(2)\n",
            "memory usage: 859.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia68Fy-dWQjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Splitting the target and independent variables\n",
        "X= churn.drop(['Exited'],axis=1)\n",
        "y=churn['Exited']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZd5S46sW6J-",
        "colab_type": "code",
        "outputId": "3f9a502b-5533-4988-ed16-fe8fd25ef175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 10)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWhKEGZgZ_Oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## One-hot encoding the categorical columns in the independent variables and dropping the first column as string values cannot be analysed \n",
        "## and these categorical columns are considered important in this analysis\n",
        "X = pd.get_dummies(X, prefix_sep='_', drop_first=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sla2KqO2aCR-",
        "colab_type": "code",
        "outputId": "e254243b-581b-4730-c007-f4953b76b21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "      <th>Gender_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore  Age  Tenure  ...  Geography_Germany  Geography_Spain  Gender_Male\n",
              "0          619   42       2  ...                  0                0            0\n",
              "1          608   41       1  ...                  0                1            0\n",
              "2          502   42       8  ...                  0                0            0\n",
              "3          699   39       1  ...                  0                0            0\n",
              "4          850   43       2  ...                  0                1            0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFvIKL59KFp7",
        "colab_type": "code",
        "outputId": "16f08e2c-b3c4-47ab-d6ae-203f888b4547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    0\n",
              "2    1\n",
              "3    0\n",
              "4    0\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-OWQy9satTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Spliiting into train and test data at ratio of 70:30\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H2PnL-9b5US",
        "colab_type": "code",
        "outputId": "a6b45bc3-31c7-4505-f6e1-88a527afc578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "X_train.describe()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "      <th>Gender_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "      <td>7000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>648.893143</td>\n",
              "      <td>38.712714</td>\n",
              "      <td>5.007429</td>\n",
              "      <td>75908.694407</td>\n",
              "      <td>1.530143</td>\n",
              "      <td>0.703571</td>\n",
              "      <td>0.514714</td>\n",
              "      <td>100057.818634</td>\n",
              "      <td>0.249429</td>\n",
              "      <td>0.247571</td>\n",
              "      <td>0.550571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>97.073946</td>\n",
              "      <td>10.401960</td>\n",
              "      <td>2.888399</td>\n",
              "      <td>62490.258613</td>\n",
              "      <td>0.580637</td>\n",
              "      <td>0.456715</td>\n",
              "      <td>0.499819</td>\n",
              "      <td>57560.085944</td>\n",
              "      <td>0.432713</td>\n",
              "      <td>0.431632</td>\n",
              "      <td>0.497471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>350.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.580000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>582.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50743.832500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>650.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>96600.990000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100561.895000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>715.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>127304.595000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>149458.040000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>850.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>250898.090000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>199970.740000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       CreditScore          Age  ...  Geography_Spain  Gender_Male\n",
              "count  7000.000000  7000.000000  ...      7000.000000  7000.000000\n",
              "mean    648.893143    38.712714  ...         0.247571     0.550571\n",
              "std      97.073946    10.401960  ...         0.431632     0.497471\n",
              "min     350.000000    18.000000  ...         0.000000     0.000000\n",
              "25%     582.000000    32.000000  ...         0.000000     0.000000\n",
              "50%     650.000000    37.000000  ...         0.000000     1.000000\n",
              "75%     715.000000    44.000000  ...         0.000000     1.000000\n",
              "max     850.000000    92.000000  ...         1.000000     1.000000\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr5Fk9Q7efHT",
        "colab_type": "code",
        "outputId": "e5ee78bb-9745-4c0e-b5ae-8e4fc156200a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "X_test.describe()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "      <th>Gender_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>654.345333</td>\n",
              "      <td>39.409667</td>\n",
              "      <td>5.025333</td>\n",
              "      <td>77832.677343</td>\n",
              "      <td>1.530333</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.516000</td>\n",
              "      <td>100165.889457</td>\n",
              "      <td>0.254333</td>\n",
              "      <td>0.248000</td>\n",
              "      <td>0.534333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>95.571848</td>\n",
              "      <td>10.671260</td>\n",
              "      <td>2.901407</td>\n",
              "      <td>62169.761924</td>\n",
              "      <td>0.584118</td>\n",
              "      <td>0.453838</td>\n",
              "      <td>0.499827</td>\n",
              "      <td>57404.122377</td>\n",
              "      <td>0.435558</td>\n",
              "      <td>0.431924</td>\n",
              "      <td>0.498903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>350.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>106.670000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>588.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>51834.342500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>655.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>98439.220000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>98772.465000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>722.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>128492.590000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>148782.695000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>850.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>238387.560000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>199992.480000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       CreditScore          Age  ...  Geography_Spain  Gender_Male\n",
              "count  3000.000000  3000.000000  ...      3000.000000  3000.000000\n",
              "mean    654.345333    39.409667  ...         0.248000     0.534333\n",
              "std      95.571848    10.671260  ...         0.431924     0.498903\n",
              "min     350.000000    18.000000  ...         0.000000     0.000000\n",
              "25%     588.000000    32.000000  ...         0.000000     0.000000\n",
              "50%     655.000000    38.000000  ...         0.000000     1.000000\n",
              "75%     722.000000    45.000000  ...         0.000000     1.000000\n",
              "max     850.000000    92.000000  ...         1.000000     1.000000\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ljn4xRta5uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Standardising and Normalizing the data before going into the actual analysis so that mean is 0 and std.deviation is 1 approximately.\n",
        "## To ensure that there is no huge variation in values between independent variables as the result will be biased towards the variable with greater values\n",
        "scaler = StandardScaler()\n",
        "X_train1 = scaler.fit_transform( X_train )\n",
        "X_test1 = scaler.transform( X_test )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbdFxdqCdbRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Imputing the standardised values into X.\n",
        "X_train=pd.DataFrame(X_train1,index=X_train.index,columns=X_train.columns)\n",
        "X_test=pd.DataFrame(X_test1,index=X_test.index,columns=X_test.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9aJmtWId8tL",
        "colab_type": "code",
        "outputId": "be435ac9-48fd-42bc-acb9-f5e7835887eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "X_train.describe()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "      <th>Gender_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7.000000e+03</td>\n",
              "      <td>7.000000e+03</td>\n",
              "      <td>7.000000e+03</td>\n",
              "      <td>7.000000e+03</td>\n",
              "      <td>7.000000e+03</td>\n",
              "      <td>7.000000e+03</td>\n",
              "      <td>7.000000e+03</td>\n",
              "      <td>7.000000e+03</td>\n",
              "      <td>7.000000e+03</td>\n",
              "      <td>7.000000e+03</td>\n",
              "      <td>7.000000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.447566e-16</td>\n",
              "      <td>1.243093e-16</td>\n",
              "      <td>5.054687e-17</td>\n",
              "      <td>-1.973342e-16</td>\n",
              "      <td>9.072108e-18</td>\n",
              "      <td>-6.186797e-16</td>\n",
              "      <td>-9.773135e-17</td>\n",
              "      <td>-1.256455e-16</td>\n",
              "      <td>5.544137e-16</td>\n",
              "      <td>4.808852e-16</td>\n",
              "      <td>-1.196820e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000071e+00</td>\n",
              "      <td>1.000071e+00</td>\n",
              "      <td>1.000071e+00</td>\n",
              "      <td>1.000071e+00</td>\n",
              "      <td>1.000071e+00</td>\n",
              "      <td>1.000071e+00</td>\n",
              "      <td>1.000071e+00</td>\n",
              "      <td>1.000071e+00</td>\n",
              "      <td>1.000071e+00</td>\n",
              "      <td>1.000071e+00</td>\n",
              "      <td>1.000071e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-3.079245e+00</td>\n",
              "      <td>-1.991374e+00</td>\n",
              "      <td>-1.733758e+00</td>\n",
              "      <td>-1.214815e+00</td>\n",
              "      <td>-9.131015e-01</td>\n",
              "      <td>-1.540615e+00</td>\n",
              "      <td>-1.029875e+00</td>\n",
              "      <td>-1.738242e+00</td>\n",
              "      <td>-5.764705e-01</td>\n",
              "      <td>-5.736112e-01</td>\n",
              "      <td>-1.106819e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-6.891439e-01</td>\n",
              "      <td>-6.453777e-01</td>\n",
              "      <td>-1.041284e+00</td>\n",
              "      <td>-1.214815e+00</td>\n",
              "      <td>-9.131015e-01</td>\n",
              "      <td>-1.540615e+00</td>\n",
              "      <td>-1.029875e+00</td>\n",
              "      <td>-8.568005e-01</td>\n",
              "      <td>-5.764705e-01</td>\n",
              "      <td>-5.736112e-01</td>\n",
              "      <td>-1.106819e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.140302e-02</td>\n",
              "      <td>-1.646648e-01</td>\n",
              "      <td>-2.572048e-03</td>\n",
              "      <td>3.311520e-01</td>\n",
              "      <td>-9.131015e-01</td>\n",
              "      <td>6.490915e-01</td>\n",
              "      <td>9.709920e-01</td>\n",
              "      <td>8.758020e-03</td>\n",
              "      <td>-5.764705e-01</td>\n",
              "      <td>-5.736112e-01</td>\n",
              "      <td>9.034903e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.810435e-01</td>\n",
              "      <td>5.083334e-01</td>\n",
              "      <td>6.899024e-01</td>\n",
              "      <td>8.225214e-01</td>\n",
              "      <td>8.092673e-01</td>\n",
              "      <td>6.490915e-01</td>\n",
              "      <td>9.709920e-01</td>\n",
              "      <td>8.582988e-01</td>\n",
              "      <td>-5.764705e-01</td>\n",
              "      <td>-5.736112e-01</td>\n",
              "      <td>9.034903e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.071835e+00</td>\n",
              "      <td>5.123178e+00</td>\n",
              "      <td>1.728614e+00</td>\n",
              "      <td>2.800467e+00</td>\n",
              "      <td>4.254005e+00</td>\n",
              "      <td>6.490915e-01</td>\n",
              "      <td>9.709920e-01</td>\n",
              "      <td>1.735926e+00</td>\n",
              "      <td>1.734694e+00</td>\n",
              "      <td>1.743341e+00</td>\n",
              "      <td>9.034903e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        CreditScore           Age  ...  Geography_Spain   Gender_Male\n",
              "count  7.000000e+03  7.000000e+03  ...     7.000000e+03  7.000000e+03\n",
              "mean   2.447566e-16  1.243093e-16  ...     4.808852e-16 -1.196820e-16\n",
              "std    1.000071e+00  1.000071e+00  ...     1.000071e+00  1.000071e+00\n",
              "min   -3.079245e+00 -1.991374e+00  ...    -5.736112e-01 -1.106819e+00\n",
              "25%   -6.891439e-01 -6.453777e-01  ...    -5.736112e-01 -1.106819e+00\n",
              "50%    1.140302e-02 -1.646648e-01  ...    -5.736112e-01  9.034903e-01\n",
              "75%    6.810435e-01  5.083334e-01  ...    -5.736112e-01  9.034903e-01\n",
              "max    2.071835e+00  5.123178e+00  ...     1.743341e+00  9.034903e-01\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzBzGOavelyE",
        "colab_type": "code",
        "outputId": "3d5049ac-20e1-4bba-d846-dc7b01f1d263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "X_test.describe()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "      <th>Gender_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.056169</td>\n",
              "      <td>0.067007</td>\n",
              "      <td>0.006199</td>\n",
              "      <td>0.030791</td>\n",
              "      <td>0.000328</td>\n",
              "      <td>0.014077</td>\n",
              "      <td>0.002573</td>\n",
              "      <td>0.001878</td>\n",
              "      <td>0.011336</td>\n",
              "      <td>0.000993</td>\n",
              "      <td>-0.032644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.984597</td>\n",
              "      <td>1.025963</td>\n",
              "      <td>1.004575</td>\n",
              "      <td>0.994942</td>\n",
              "      <td>1.006066</td>\n",
              "      <td>0.993771</td>\n",
              "      <td>1.000088</td>\n",
              "      <td>0.997362</td>\n",
              "      <td>1.006647</td>\n",
              "      <td>1.000747</td>\n",
              "      <td>1.002949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-3.079245</td>\n",
              "      <td>-1.991374</td>\n",
              "      <td>-1.733758</td>\n",
              "      <td>-1.214815</td>\n",
              "      <td>-0.913102</td>\n",
              "      <td>-1.540615</td>\n",
              "      <td>-1.029875</td>\n",
              "      <td>-1.736590</td>\n",
              "      <td>-0.576470</td>\n",
              "      <td>-0.573611</td>\n",
              "      <td>-1.106819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.627331</td>\n",
              "      <td>-0.645378</td>\n",
              "      <td>-0.695047</td>\n",
              "      <td>-1.214815</td>\n",
              "      <td>-0.913102</td>\n",
              "      <td>-1.540615</td>\n",
              "      <td>-1.029875</td>\n",
              "      <td>-0.837854</td>\n",
              "      <td>-0.576470</td>\n",
              "      <td>-0.573611</td>\n",
              "      <td>-1.106819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.062914</td>\n",
              "      <td>-0.068522</td>\n",
              "      <td>-0.002572</td>\n",
              "      <td>0.360570</td>\n",
              "      <td>-0.913102</td>\n",
              "      <td>0.649092</td>\n",
              "      <td>0.970992</td>\n",
              "      <td>-0.022332</td>\n",
              "      <td>-0.576470</td>\n",
              "      <td>-0.573611</td>\n",
              "      <td>0.903490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.753159</td>\n",
              "      <td>0.604476</td>\n",
              "      <td>1.036140</td>\n",
              "      <td>0.841534</td>\n",
              "      <td>0.809267</td>\n",
              "      <td>0.649092</td>\n",
              "      <td>0.970992</td>\n",
              "      <td>0.846565</td>\n",
              "      <td>1.734694</td>\n",
              "      <td>-0.573611</td>\n",
              "      <td>0.903490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.071835</td>\n",
              "      <td>5.123178</td>\n",
              "      <td>1.728614</td>\n",
              "      <td>2.600253</td>\n",
              "      <td>4.254005</td>\n",
              "      <td>0.649092</td>\n",
              "      <td>0.970992</td>\n",
              "      <td>1.736304</td>\n",
              "      <td>1.734694</td>\n",
              "      <td>1.743341</td>\n",
              "      <td>0.903490</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       CreditScore          Age  ...  Geography_Spain  Gender_Male\n",
              "count  3000.000000  3000.000000  ...      3000.000000  3000.000000\n",
              "mean      0.056169     0.067007  ...         0.000993    -0.032644\n",
              "std       0.984597     1.025963  ...         1.000747     1.002949\n",
              "min      -3.079245    -1.991374  ...        -0.573611    -1.106819\n",
              "25%      -0.627331    -0.645378  ...        -0.573611    -1.106819\n",
              "50%       0.062914    -0.068522  ...        -0.573611     0.903490\n",
              "75%       0.753159     0.604476  ...        -0.573611     0.903490\n",
              "max       2.071835     5.123178  ...         1.743341     0.903490\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESYE80OlbR2z",
        "colab_type": "code",
        "outputId": "ffba15ab-4419-4ad4-c24c-5796998fef88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "## Checking the dimesnion of train and test data\n",
        "print('training shapes:', {X_train.shape}, {y_train.shape})\n",
        "print('testing shapes:' ,{X_test.shape}, {y_test.shape})"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training shapes: {(7000, 11)} {(7000,)}\n",
            "testing shapes: {(3000, 11)} {(3000,)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7JNdatFHCs7",
        "colab_type": "text"
      },
      "source": [
        "# **Initialising and Building Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wA7cdXMHZYJ",
        "colab_type": "code",
        "outputId": "881901bc-21db-480c-c484-69558c554483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Initialising the latest tensorflow version\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEVyROrsQZgr",
        "colab_type": "text"
      },
      "source": [
        "# **Defining a Sequential Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4He91HWMUTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Initialising a sequential model\n",
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFIfX73oQ3Se",
        "colab_type": "text"
      },
      "source": [
        "**Adding the output layer to the model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHMe6IWtMe1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Adding the output layer to the model with a single neuron , input shape as 11 as there are only 11 inputs and keeping activation as Sigmoid as its a binary classifier\n",
        "model.add(tf.keras.layers.Dense(1,input_shape=(11,), activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dXoHOSLQ8K-",
        "colab_type": "text"
      },
      "source": [
        "**Compiling the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WgFxvR_Q_PF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Compiling model with SGD optimizer, binary crossentropy loss function as its a binary classification, and measuring metric is accuracy score.\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OihXbYe9RIL2",
        "colab_type": "text"
      },
      "source": [
        "**Summarize the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGy17vuoRLoA",
        "colab_type": "code",
        "outputId": "6c94b8c1-8296-4c6b-f73f-396988605307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "## Displaying the summary statistics of the model to check total no of trainanble and non-trainable parameters.\n",
        "model.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 1)                 12        \n",
            "=================================================================\n",
            "Total params: 12\n",
            "Trainable params: 12\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpvyzABiRVtn",
        "colab_type": "code",
        "outputId": "44972906-7dbf-4d03-8e1c-bd30423dbc71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## Fitting the model on train data and validating it on the test data with 50 epochs\n",
        "model.fit(X_train,y_train, validation_data=(X_test, y_test), epochs=50)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7000 samples, validate on 3000 samples\n",
            "Epoch 1/50\n",
            "7000/7000 [==============================] - 1s 114us/sample - loss: 0.7155 - accuracy: 0.5814 - val_loss: 0.6210 - val_accuracy: 0.6747\n",
            "Epoch 2/50\n",
            "7000/7000 [==============================] - 1s 72us/sample - loss: 0.5540 - accuracy: 0.7457 - val_loss: 0.5206 - val_accuracy: 0.7817\n",
            "Epoch 3/50\n",
            "7000/7000 [==============================] - 0s 67us/sample - loss: 0.4894 - accuracy: 0.7951 - val_loss: 0.4782 - val_accuracy: 0.8050\n",
            "Epoch 4/50\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.4613 - accuracy: 0.8039 - val_loss: 0.4578 - val_accuracy: 0.8127\n",
            "Epoch 5/50\n",
            "7000/7000 [==============================] - 0s 62us/sample - loss: 0.4474 - accuracy: 0.8056 - val_loss: 0.4470 - val_accuracy: 0.8177\n",
            "Epoch 6/50\n",
            "7000/7000 [==============================] - 0s 65us/sample - loss: 0.4400 - accuracy: 0.8059 - val_loss: 0.4410 - val_accuracy: 0.8177\n",
            "Epoch 7/50\n",
            "7000/7000 [==============================] - 0s 66us/sample - loss: 0.4356 - accuracy: 0.8073 - val_loss: 0.4372 - val_accuracy: 0.8180\n",
            "Epoch 8/50\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.4330 - accuracy: 0.8083 - val_loss: 0.4350 - val_accuracy: 0.8167\n",
            "Epoch 9/50\n",
            "7000/7000 [==============================] - 0s 62us/sample - loss: 0.4314 - accuracy: 0.8080 - val_loss: 0.4335 - val_accuracy: 0.8157\n",
            "Epoch 10/50\n",
            "7000/7000 [==============================] - 0s 70us/sample - loss: 0.4302 - accuracy: 0.8089 - val_loss: 0.4325 - val_accuracy: 0.8170\n",
            "Epoch 11/50\n",
            "7000/7000 [==============================] - 0s 65us/sample - loss: 0.4295 - accuracy: 0.8081 - val_loss: 0.4319 - val_accuracy: 0.8170\n",
            "Epoch 12/50\n",
            "7000/7000 [==============================] - 0s 65us/sample - loss: 0.4290 - accuracy: 0.8087 - val_loss: 0.4314 - val_accuracy: 0.8173\n",
            "Epoch 13/50\n",
            "7000/7000 [==============================] - 0s 66us/sample - loss: 0.4286 - accuracy: 0.8097 - val_loss: 0.4311 - val_accuracy: 0.8190\n",
            "Epoch 14/50\n",
            "7000/7000 [==============================] - 0s 68us/sample - loss: 0.4284 - accuracy: 0.8080 - val_loss: 0.4308 - val_accuracy: 0.8187\n",
            "Epoch 15/50\n",
            "7000/7000 [==============================] - 0s 66us/sample - loss: 0.4282 - accuracy: 0.8084 - val_loss: 0.4307 - val_accuracy: 0.8187\n",
            "Epoch 16/50\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.4281 - accuracy: 0.8083 - val_loss: 0.4306 - val_accuracy: 0.8180\n",
            "Epoch 17/50\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.4280 - accuracy: 0.8077 - val_loss: 0.4305 - val_accuracy: 0.8177\n",
            "Epoch 18/50\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.4280 - accuracy: 0.8074 - val_loss: 0.4305 - val_accuracy: 0.8177\n",
            "Epoch 19/50\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.4279 - accuracy: 0.8074 - val_loss: 0.4305 - val_accuracy: 0.8173\n",
            "Epoch 20/50\n",
            "7000/7000 [==============================] - 0s 66us/sample - loss: 0.4279 - accuracy: 0.8074 - val_loss: 0.4305 - val_accuracy: 0.8173\n",
            "Epoch 21/50\n",
            "7000/7000 [==============================] - 0s 65us/sample - loss: 0.4279 - accuracy: 0.8076 - val_loss: 0.4304 - val_accuracy: 0.8173\n",
            "Epoch 22/50\n",
            "7000/7000 [==============================] - 0s 65us/sample - loss: 0.4278 - accuracy: 0.8070 - val_loss: 0.4304 - val_accuracy: 0.8173\n",
            "Epoch 23/50\n",
            "7000/7000 [==============================] - 0s 65us/sample - loss: 0.4278 - accuracy: 0.8076 - val_loss: 0.4305 - val_accuracy: 0.8177\n",
            "Epoch 24/50\n",
            "7000/7000 [==============================] - 0s 67us/sample - loss: 0.4278 - accuracy: 0.8073 - val_loss: 0.4304 - val_accuracy: 0.8173\n",
            "Epoch 25/50\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.4278 - accuracy: 0.8071 - val_loss: 0.4304 - val_accuracy: 0.8173\n",
            "Epoch 26/50\n",
            "7000/7000 [==============================] - 0s 66us/sample - loss: 0.4278 - accuracy: 0.8087 - val_loss: 0.4304 - val_accuracy: 0.8173\n",
            "Epoch 27/50\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.4278 - accuracy: 0.8087 - val_loss: 0.4304 - val_accuracy: 0.8173\n",
            "Epoch 28/50\n",
            "7000/7000 [==============================] - 0s 70us/sample - loss: 0.4278 - accuracy: 0.8074 - val_loss: 0.4304 - val_accuracy: 0.8160\n",
            "Epoch 29/50\n",
            "7000/7000 [==============================] - 0s 62us/sample - loss: 0.4278 - accuracy: 0.8074 - val_loss: 0.4303 - val_accuracy: 0.8173\n",
            "Epoch 30/50\n",
            "7000/7000 [==============================] - 0s 60us/sample - loss: 0.4278 - accuracy: 0.8080 - val_loss: 0.4304 - val_accuracy: 0.8177\n",
            "Epoch 31/50\n",
            "7000/7000 [==============================] - 0s 62us/sample - loss: 0.4278 - accuracy: 0.8074 - val_loss: 0.4304 - val_accuracy: 0.8177\n",
            "Epoch 32/50\n",
            "7000/7000 [==============================] - 0s 62us/sample - loss: 0.4278 - accuracy: 0.8089 - val_loss: 0.4304 - val_accuracy: 0.8177\n",
            "Epoch 33/50\n",
            "7000/7000 [==============================] - 1s 72us/sample - loss: 0.4278 - accuracy: 0.8079 - val_loss: 0.4305 - val_accuracy: 0.8173\n",
            "Epoch 34/50\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.4278 - accuracy: 0.8067 - val_loss: 0.4304 - val_accuracy: 0.8163\n",
            "Epoch 35/50\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.4278 - accuracy: 0.8086 - val_loss: 0.4305 - val_accuracy: 0.8167\n",
            "Epoch 36/50\n",
            "7000/7000 [==============================] - 0s 66us/sample - loss: 0.4278 - accuracy: 0.8074 - val_loss: 0.4304 - val_accuracy: 0.8170\n",
            "Epoch 37/50\n",
            "7000/7000 [==============================] - 0s 65us/sample - loss: 0.4278 - accuracy: 0.8079 - val_loss: 0.4304 - val_accuracy: 0.8167\n",
            "Epoch 38/50\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.4278 - accuracy: 0.8077 - val_loss: 0.4304 - val_accuracy: 0.8163\n",
            "Epoch 39/50\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.4278 - accuracy: 0.8079 - val_loss: 0.4304 - val_accuracy: 0.8160\n",
            "Epoch 40/50\n",
            "7000/7000 [==============================] - 0s 67us/sample - loss: 0.4278 - accuracy: 0.8079 - val_loss: 0.4303 - val_accuracy: 0.8167\n",
            "Epoch 41/50\n",
            "7000/7000 [==============================] - 0s 66us/sample - loss: 0.4278 - accuracy: 0.8076 - val_loss: 0.4303 - val_accuracy: 0.8163\n",
            "Epoch 42/50\n",
            "7000/7000 [==============================] - 0s 63us/sample - loss: 0.4278 - accuracy: 0.8073 - val_loss: 0.4304 - val_accuracy: 0.8163\n",
            "Epoch 43/50\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.4278 - accuracy: 0.8077 - val_loss: 0.4304 - val_accuracy: 0.8163\n",
            "Epoch 44/50\n",
            "7000/7000 [==============================] - 0s 68us/sample - loss: 0.4278 - accuracy: 0.8080 - val_loss: 0.4304 - val_accuracy: 0.8170\n",
            "Epoch 45/50\n",
            "7000/7000 [==============================] - 0s 65us/sample - loss: 0.4278 - accuracy: 0.8074 - val_loss: 0.4303 - val_accuracy: 0.8170\n",
            "Epoch 46/50\n",
            "7000/7000 [==============================] - 0s 62us/sample - loss: 0.4278 - accuracy: 0.8077 - val_loss: 0.4303 - val_accuracy: 0.8167\n",
            "Epoch 47/50\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.4278 - accuracy: 0.8083 - val_loss: 0.4304 - val_accuracy: 0.8160\n",
            "Epoch 48/50\n",
            "7000/7000 [==============================] - 0s 67us/sample - loss: 0.4278 - accuracy: 0.8086 - val_loss: 0.4305 - val_accuracy: 0.8160\n",
            "Epoch 49/50\n",
            "7000/7000 [==============================] - 0s 65us/sample - loss: 0.4278 - accuracy: 0.8071 - val_loss: 0.4304 - val_accuracy: 0.8163\n",
            "Epoch 50/50\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.4278 - accuracy: 0.8079 - val_loss: 0.4304 - val_accuracy: 0.8173\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7feb7d9bb5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddrB3iKZrSsT",
        "colab_type": "text"
      },
      "source": [
        "Loss is found to be more and accuracy is somewhat lesser. Inorder to have a better accuracy and less loss, trying to optimise the model using more hidden layers and making use of learning rate and dropout rates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA-6_GHS9B91",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7ad4a2ae-5b16-4cbb-910f-3fd2cf24ae11"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, (model.predict(X_test)>0.5).astype(int)))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.96      0.89      2401\n",
            "           1       0.60      0.25      0.35       599\n",
            "\n",
            "    accuracy                           0.82      3000\n",
            "   macro avg       0.72      0.60      0.62      3000\n",
            "weighted avg       0.79      0.82      0.79      3000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bx6YfHERhdh",
        "colab_type": "text"
      },
      "source": [
        "## **Optimizing the model by adding a hidden layer and using learning rate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjOl2r4IRr0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Creating a sequential model\n",
        "model1 = tf.keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3JGloh2R2WW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add Dense Layer which has 110 neurons and applying sigmoid activation with 11 inputs\n",
        "model1.add(tf.keras.layers.Dense(110,input_shape=(11,), activation='sigmoid'))\n",
        "\n",
        "# Normalize the data\n",
        "model1.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "## Adding a droupout rate of 5% so that during each epoch some neurons are dropped so that each and every neuron are trained with the data atleast once\n",
        "model1.add(tf.keras.layers.Dropout(rate=0.05))\n",
        "\n",
        "# Add another Dense Layer which has 110 neurons and applying sigmoid activation\n",
        "model1.add(tf.keras.layers.Dense(110, activation='sigmoid'))\n",
        "\n",
        "## Adding a droupout rate of 5% so that during each epoch some neurons are dropped so that each and every neuron are trained with the data atleast once\n",
        "model1.add(tf.keras.layers.Dropout(rate=0.05))\n",
        "\n",
        "# Add output Dense Layer which has 1 neuron which provides final binary output and applying sigmoid activation\n",
        "model1.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt-MEPbGShw4",
        "colab_type": "code",
        "outputId": "3d2e66ea-be02-4324-b808-06cb1a5748f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "## Displaying the summary of the model created\n",
        "model1.summary()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 110)               1320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 110)               440       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 110)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 110)               12210     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 110)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 111       \n",
            "=================================================================\n",
            "Total params: 14,081\n",
            "Trainable params: 13,861\n",
            "Non-trainable params: 220\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1IhrlbWdA2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Initialising a learning rate to have a optimal gradient descent ( acceptable range of minimium error)\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "learning_rate=0.03\n",
        "sgd = SGD(lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McmQmNT5S2fP",
        "colab_type": "code",
        "outputId": "fe3d62ac-f5c8-44c4-a464-8b96d3ffb342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## Compiling model with SGD optimizer, binary crossentropy loss function as its a binary classification, and measuring metric is accuracy score.\n",
        "## Fitting the model on train data and validating it on the test data with 50 epochs\n",
        "model1.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history=model1.fit(X_train, y_train, validation_data=(X_test, y_test),epochs=50)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7000 samples, validate on 3000 samples\n",
            "Epoch 1/50\n",
            "7000/7000 [==============================] - 1s 186us/sample - loss: 0.4736 - accuracy: 0.7909 - val_loss: 0.4703 - val_accuracy: 0.8003\n",
            "Epoch 2/50\n",
            "7000/7000 [==============================] - 1s 87us/sample - loss: 0.4312 - accuracy: 0.8079 - val_loss: 0.4343 - val_accuracy: 0.8107\n",
            "Epoch 3/50\n",
            "7000/7000 [==============================] - 1s 90us/sample - loss: 0.4306 - accuracy: 0.8071 - val_loss: 0.4268 - val_accuracy: 0.8190\n",
            "Epoch 4/50\n",
            "7000/7000 [==============================] - 1s 85us/sample - loss: 0.4286 - accuracy: 0.8084 - val_loss: 0.4244 - val_accuracy: 0.8203\n",
            "Epoch 5/50\n",
            "7000/7000 [==============================] - 1s 90us/sample - loss: 0.4268 - accuracy: 0.8097 - val_loss: 0.4224 - val_accuracy: 0.8227\n",
            "Epoch 6/50\n",
            "7000/7000 [==============================] - 1s 89us/sample - loss: 0.4261 - accuracy: 0.8103 - val_loss: 0.4194 - val_accuracy: 0.8267\n",
            "Epoch 7/50\n",
            "7000/7000 [==============================] - 1s 86us/sample - loss: 0.4219 - accuracy: 0.8124 - val_loss: 0.4160 - val_accuracy: 0.8290\n",
            "Epoch 8/50\n",
            "7000/7000 [==============================] - 1s 89us/sample - loss: 0.4164 - accuracy: 0.8184 - val_loss: 0.4255 - val_accuracy: 0.8177\n",
            "Epoch 9/50\n",
            "7000/7000 [==============================] - 1s 91us/sample - loss: 0.4123 - accuracy: 0.8220 - val_loss: 0.4117 - val_accuracy: 0.8303\n",
            "Epoch 10/50\n",
            "7000/7000 [==============================] - 1s 89us/sample - loss: 0.4087 - accuracy: 0.8209 - val_loss: 0.4029 - val_accuracy: 0.8373\n",
            "Epoch 11/50\n",
            "7000/7000 [==============================] - 1s 91us/sample - loss: 0.4012 - accuracy: 0.8287 - val_loss: 0.4009 - val_accuracy: 0.8400\n",
            "Epoch 12/50\n",
            "7000/7000 [==============================] - 1s 89us/sample - loss: 0.4004 - accuracy: 0.8294 - val_loss: 0.3949 - val_accuracy: 0.8430\n",
            "Epoch 13/50\n",
            "7000/7000 [==============================] - 1s 91us/sample - loss: 0.3934 - accuracy: 0.8306 - val_loss: 0.3911 - val_accuracy: 0.8450\n",
            "Epoch 14/50\n",
            "7000/7000 [==============================] - 1s 85us/sample - loss: 0.3921 - accuracy: 0.8349 - val_loss: 0.3866 - val_accuracy: 0.8433\n",
            "Epoch 15/50\n",
            "7000/7000 [==============================] - 1s 92us/sample - loss: 0.3876 - accuracy: 0.8366 - val_loss: 0.3887 - val_accuracy: 0.8430\n",
            "Epoch 16/50\n",
            "7000/7000 [==============================] - 1s 88us/sample - loss: 0.3850 - accuracy: 0.8366 - val_loss: 0.3806 - val_accuracy: 0.8490\n",
            "Epoch 17/50\n",
            "7000/7000 [==============================] - 1s 83us/sample - loss: 0.3814 - accuracy: 0.8399 - val_loss: 0.3794 - val_accuracy: 0.8497\n",
            "Epoch 18/50\n",
            "7000/7000 [==============================] - 1s 94us/sample - loss: 0.3783 - accuracy: 0.8419 - val_loss: 0.3770 - val_accuracy: 0.8497\n",
            "Epoch 19/50\n",
            "7000/7000 [==============================] - 1s 89us/sample - loss: 0.3788 - accuracy: 0.8406 - val_loss: 0.3777 - val_accuracy: 0.8503\n",
            "Epoch 20/50\n",
            "7000/7000 [==============================] - 1s 86us/sample - loss: 0.3749 - accuracy: 0.8426 - val_loss: 0.3738 - val_accuracy: 0.8513\n",
            "Epoch 21/50\n",
            "7000/7000 [==============================] - 1s 89us/sample - loss: 0.3748 - accuracy: 0.8449 - val_loss: 0.3792 - val_accuracy: 0.8473\n",
            "Epoch 22/50\n",
            "7000/7000 [==============================] - 1s 88us/sample - loss: 0.3709 - accuracy: 0.8450 - val_loss: 0.3711 - val_accuracy: 0.8557\n",
            "Epoch 23/50\n",
            "7000/7000 [==============================] - 1s 84us/sample - loss: 0.3688 - accuracy: 0.8477 - val_loss: 0.3882 - val_accuracy: 0.8413\n",
            "Epoch 24/50\n",
            "7000/7000 [==============================] - 1s 98us/sample - loss: 0.3742 - accuracy: 0.8460 - val_loss: 0.3726 - val_accuracy: 0.8497\n",
            "Epoch 25/50\n",
            "7000/7000 [==============================] - 1s 88us/sample - loss: 0.3698 - accuracy: 0.8487 - val_loss: 0.3680 - val_accuracy: 0.8557\n",
            "Epoch 26/50\n",
            "7000/7000 [==============================] - 1s 88us/sample - loss: 0.3701 - accuracy: 0.8486 - val_loss: 0.3686 - val_accuracy: 0.8523\n",
            "Epoch 27/50\n",
            "7000/7000 [==============================] - 1s 90us/sample - loss: 0.3719 - accuracy: 0.8480 - val_loss: 0.3662 - val_accuracy: 0.8557\n",
            "Epoch 28/50\n",
            "7000/7000 [==============================] - 1s 94us/sample - loss: 0.3690 - accuracy: 0.8516 - val_loss: 0.3684 - val_accuracy: 0.8513\n",
            "Epoch 29/50\n",
            "7000/7000 [==============================] - 1s 87us/sample - loss: 0.3670 - accuracy: 0.8461 - val_loss: 0.3640 - val_accuracy: 0.8563\n",
            "Epoch 30/50\n",
            "7000/7000 [==============================] - 1s 88us/sample - loss: 0.3667 - accuracy: 0.8480 - val_loss: 0.3657 - val_accuracy: 0.8537\n",
            "Epoch 31/50\n",
            "7000/7000 [==============================] - 1s 88us/sample - loss: 0.3696 - accuracy: 0.8490 - val_loss: 0.3659 - val_accuracy: 0.8533\n",
            "Epoch 32/50\n",
            "7000/7000 [==============================] - 1s 89us/sample - loss: 0.3651 - accuracy: 0.8474 - val_loss: 0.3639 - val_accuracy: 0.8540\n",
            "Epoch 33/50\n",
            "7000/7000 [==============================] - 1s 82us/sample - loss: 0.3663 - accuracy: 0.8471 - val_loss: 0.3687 - val_accuracy: 0.8507\n",
            "Epoch 34/50\n",
            "7000/7000 [==============================] - 1s 86us/sample - loss: 0.3657 - accuracy: 0.8486 - val_loss: 0.3654 - val_accuracy: 0.8543\n",
            "Epoch 35/50\n",
            "7000/7000 [==============================] - 1s 87us/sample - loss: 0.3670 - accuracy: 0.8494 - val_loss: 0.3667 - val_accuracy: 0.8503\n",
            "Epoch 36/50\n",
            "7000/7000 [==============================] - 1s 86us/sample - loss: 0.3618 - accuracy: 0.8500 - val_loss: 0.3706 - val_accuracy: 0.8497\n",
            "Epoch 37/50\n",
            "7000/7000 [==============================] - 1s 91us/sample - loss: 0.3682 - accuracy: 0.8471 - val_loss: 0.3628 - val_accuracy: 0.8563\n",
            "Epoch 38/50\n",
            "7000/7000 [==============================] - 1s 89us/sample - loss: 0.3648 - accuracy: 0.8514 - val_loss: 0.3604 - val_accuracy: 0.8553\n",
            "Epoch 39/50\n",
            "7000/7000 [==============================] - 1s 85us/sample - loss: 0.3613 - accuracy: 0.8530 - val_loss: 0.3616 - val_accuracy: 0.8560\n",
            "Epoch 40/50\n",
            "7000/7000 [==============================] - 1s 95us/sample - loss: 0.3647 - accuracy: 0.8487 - val_loss: 0.3626 - val_accuracy: 0.8547\n",
            "Epoch 41/50\n",
            "7000/7000 [==============================] - 1s 93us/sample - loss: 0.3642 - accuracy: 0.8494 - val_loss: 0.3605 - val_accuracy: 0.8563\n",
            "Epoch 42/50\n",
            "7000/7000 [==============================] - 1s 98us/sample - loss: 0.3580 - accuracy: 0.8534 - val_loss: 0.3627 - val_accuracy: 0.8533\n",
            "Epoch 43/50\n",
            "7000/7000 [==============================] - 1s 94us/sample - loss: 0.3661 - accuracy: 0.8489 - val_loss: 0.3637 - val_accuracy: 0.8527\n",
            "Epoch 44/50\n",
            "7000/7000 [==============================] - 1s 87us/sample - loss: 0.3570 - accuracy: 0.8529 - val_loss: 0.3616 - val_accuracy: 0.8553\n",
            "Epoch 45/50\n",
            "7000/7000 [==============================] - 1s 83us/sample - loss: 0.3624 - accuracy: 0.8556 - val_loss: 0.3619 - val_accuracy: 0.8550\n",
            "Epoch 46/50\n",
            "7000/7000 [==============================] - 1s 92us/sample - loss: 0.3612 - accuracy: 0.8521 - val_loss: 0.3595 - val_accuracy: 0.8580\n",
            "Epoch 47/50\n",
            "7000/7000 [==============================] - 1s 84us/sample - loss: 0.3607 - accuracy: 0.8461 - val_loss: 0.3592 - val_accuracy: 0.8573\n",
            "Epoch 48/50\n",
            "7000/7000 [==============================] - 1s 86us/sample - loss: 0.3642 - accuracy: 0.8491 - val_loss: 0.3639 - val_accuracy: 0.8520\n",
            "Epoch 49/50\n",
            "7000/7000 [==============================] - 1s 95us/sample - loss: 0.3579 - accuracy: 0.8521 - val_loss: 0.3582 - val_accuracy: 0.8583\n",
            "Epoch 50/50\n",
            "7000/7000 [==============================] - 1s 88us/sample - loss: 0.3642 - accuracy: 0.8513 - val_loss: 0.3572 - val_accuracy: 0.8610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSspEi3liBVv",
        "colab_type": "text"
      },
      "source": [
        "# **Plotting the accuracy scores obtained for train and validation data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaTvqWYgiA6V",
        "colab_type": "code",
        "outputId": "f84645c5-77cd-4412-bfaa-4c0f8454be19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "plt.plot(np.array(history.history['accuracy']) * 100)\n",
        "plt.plot(np.array(history.history['val_accuracy']) * 100)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.title('Accuracy over epochs')\n",
        "plt.show()\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEcCAYAAAAoSqjDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuc7ZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X49neFTClqeI",
        "colab_type": "code",
        "outputId": "7afee399-bc89-4a5d-ae4c-b98103e540eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "## Predicting the values of target variable customer churn or not using the model built\n",
        "y_pred = model1.predict(X_test)\n",
        "print(y_pred[:10])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5478967 ]\n",
            " [0.02477037]\n",
            " [0.42569783]\n",
            " [0.18109392]\n",
            " [0.05010019]\n",
            " [0.0797213 ]\n",
            " [0.00734061]\n",
            " [0.14944384]\n",
            " [0.8395234 ]\n",
            " [0.01731607]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0oevMfpwvNB",
        "colab_type": "text"
      },
      "source": [
        "# **Predicted the results using 0.5 as a threshold**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0SQLRBHmBLC",
        "colab_type": "code",
        "outputId": "0befd914-ef94-485a-b625-1dc821281daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "print(y_pred[:10])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEVH-YPVx7JV",
        "colab_type": "text"
      },
      "source": [
        "## **Printing the Accuracy score and confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHfBU0cqmMqB",
        "colab_type": "code",
        "outputId": "e1ac81e0-654f-42db-8d07-a9515b941fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "## Printing the confusion matrix to find the total number of correctly predicted results\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "plt.figure(figsize = (5,5))\n",
        "plt.title(\"Confusion Matrix\")\n",
        "sns.heatmap(cm,annot=True,fmt='g')\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.xlabel(\"Predicted\")"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2319   82]\n",
            " [ 335  264]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 21.5, 'Predicted')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAFSCAYAAABPFzzRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwVREJAAFUxGRABRMRUQCUDAVEQng/wOZd7nR+cA3WAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AXWC01kxV-Y",
        "colab_type": "text"
      },
      "source": [
        "Out of the 3000 values, 2583 values are being correctly classified by the above initialised Neural Networks model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4Bc1bPXmbZK",
        "colab_type": "code",
        "outputId": "e81cc2db-53c5-4048-b836-499084a42349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Printing the accuracy score of the model on predictions made on test data.\n",
        "print((metrics.accuracy_score(y_test,y_pred)*100),'% of testing data was classified correctly')"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86.1 % of testing data was classified correctly\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnhYlDmqvnH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "f1724f73-8487-4286-a75d-21864218bb21"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.92      2401\n",
            "           1       0.76      0.44      0.56       599\n",
            "\n",
            "    accuracy                           0.86      3000\n",
            "   macro avg       0.82      0.70      0.74      3000\n",
            "weighted avg       0.85      0.86      0.85      3000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcUOf3IvO-KO",
        "colab_type": "text"
      },
      "source": [
        "**Comparing the classification report obtained from the above two models, it is evident that,**\n",
        "\n",
        "**Precision, recall, f1score and accuracy are more for the optimised model and its able to predict the results in a better way comparitively in a model with only one neuron.**\n",
        "\n",
        "**The more number of hidden layers, dropout and learning rate help in achieving the better model parameters.** "
      ]
    }
  ]
}